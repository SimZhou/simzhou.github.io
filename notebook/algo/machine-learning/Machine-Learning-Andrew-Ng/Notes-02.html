<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Simon’s Notebook</title>
    <meta name="generator" content="VuePress 1.5.3">
    <link rel="icon" href="/notebook/doraemon_winter_circle.png">
    <meta name="description" content="A Technical Notebook - Simon的技术笔记">
    <link rel="preload" href="/notebook/assets/css/0.styles.8d6e7e33.css" as="style"><link rel="preload" href="/notebook/assets/js/app.1fe6bb95.js" as="script"><link rel="preload" href="/notebook/assets/js/2.4f4438fc.js" as="script"><link rel="preload" href="/notebook/assets/js/3.a73bf4c2.js" as="script"><link rel="prefetch" href="/notebook/assets/js/10.e27e6bfd.js"><link rel="prefetch" href="/notebook/assets/js/11.a9bdaef7.js"><link rel="prefetch" href="/notebook/assets/js/12.9a407165.js"><link rel="prefetch" href="/notebook/assets/js/13.4ff47a1a.js"><link rel="prefetch" href="/notebook/assets/js/14.8edd2b1c.js"><link rel="prefetch" href="/notebook/assets/js/15.1bbb40b9.js"><link rel="prefetch" href="/notebook/assets/js/16.80e14f74.js"><link rel="prefetch" href="/notebook/assets/js/17.abe3fe58.js"><link rel="prefetch" href="/notebook/assets/js/18.0a90cd41.js"><link rel="prefetch" href="/notebook/assets/js/19.aaa1abbd.js"><link rel="prefetch" href="/notebook/assets/js/20.8f759f86.js"><link rel="prefetch" href="/notebook/assets/js/21.2f24f0a4.js"><link rel="prefetch" href="/notebook/assets/js/22.bcfac0ba.js"><link rel="prefetch" href="/notebook/assets/js/23.81789ecf.js"><link rel="prefetch" href="/notebook/assets/js/24.23f87722.js"><link rel="prefetch" href="/notebook/assets/js/25.1f512bc7.js"><link rel="prefetch" href="/notebook/assets/js/26.894f48df.js"><link rel="prefetch" href="/notebook/assets/js/27.3349098a.js"><link rel="prefetch" href="/notebook/assets/js/28.c29c6d5d.js"><link rel="prefetch" href="/notebook/assets/js/29.747472f0.js"><link rel="prefetch" href="/notebook/assets/js/30.d8a6be30.js"><link rel="prefetch" href="/notebook/assets/js/31.57e61126.js"><link rel="prefetch" href="/notebook/assets/js/32.41de60fc.js"><link rel="prefetch" href="/notebook/assets/js/33.0dfd42c0.js"><link rel="prefetch" href="/notebook/assets/js/34.bdab3f8e.js"><link rel="prefetch" href="/notebook/assets/js/35.4d6488e5.js"><link rel="prefetch" href="/notebook/assets/js/36.79031677.js"><link rel="prefetch" href="/notebook/assets/js/37.169fd0c3.js"><link rel="prefetch" href="/notebook/assets/js/38.7f8ab325.js"><link rel="prefetch" href="/notebook/assets/js/39.d5cd159c.js"><link rel="prefetch" href="/notebook/assets/js/4.d8fd618f.js"><link rel="prefetch" href="/notebook/assets/js/40.f5f8cefc.js"><link rel="prefetch" href="/notebook/assets/js/41.7de7e6b2.js"><link rel="prefetch" href="/notebook/assets/js/42.bc682495.js"><link rel="prefetch" href="/notebook/assets/js/43.b4d7907d.js"><link rel="prefetch" href="/notebook/assets/js/44.d01b506d.js"><link rel="prefetch" href="/notebook/assets/js/5.903e51f7.js"><link rel="prefetch" href="/notebook/assets/js/6.15ae8491.js"><link rel="prefetch" href="/notebook/assets/js/7.0967e6c0.js"><link rel="prefetch" href="/notebook/assets/js/8.271adfcc.js"><link rel="prefetch" href="/notebook/assets/js/9.be0c7e0e.js">
    <link rel="stylesheet" href="/notebook/assets/css/0.styles.8d6e7e33.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/notebook/" class="home-link router-link-active"><img src="/notebook/doraemon_winter_circle.png" alt="Simon’s Notebook" class="logo"> <span class="site-name can-hide">Simon’s Notebook</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/notebook/guide/" class="nav-link">
  导航
</a></div><div class="nav-item"><a href="/notebook/resource/" class="nav-link">
  资源
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法" class="dropdown-title"><span class="title">算法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/algo/" class="nav-link router-link-active">
  算法导航页
</a></li><li class="dropdown-item"><h4>
          算法与数据结构
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/algo/ds-algo/pending.html" class="nav-link">
  算法与数据结构
</a></li><li class="dropdown-subitem"><a href="/notebook/algo/ds-algo/leetcode/" class="nav-link">
  Leetcode刷题总结
</a></li></ul></li><li class="dropdown-item"><h4>
          机器学习
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/algo/machine-learning/ml_big_map.html" class="nav-link">
  机器学习算法
</a></li><li class="dropdown-subitem"><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-01.html" class="nav-link">
  吴恩达《机器学习公开课》笔记
</a></li></ul></li></ul></div></div><div class="nav-item"><a href="/notebook/nlp/" class="nav-link">
  NLP
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="/cs-basics/" class="dropdown-title"><span class="title">计算机基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/cs-basics/network/" class="nav-link">
  计算机网络
</a></li></ul></div></div><div class="nav-item"><a href="/notebook/reading/" class="nav-link">
  阅读
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/notebook/guide/" class="nav-link">
  导航
</a></div><div class="nav-item"><a href="/notebook/resource/" class="nav-link">
  资源
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法" class="dropdown-title"><span class="title">算法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/algo/" class="nav-link router-link-active">
  算法导航页
</a></li><li class="dropdown-item"><h4>
          算法与数据结构
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/algo/ds-algo/pending.html" class="nav-link">
  算法与数据结构
</a></li><li class="dropdown-subitem"><a href="/notebook/algo/ds-algo/leetcode/" class="nav-link">
  Leetcode刷题总结
</a></li></ul></li><li class="dropdown-item"><h4>
          机器学习
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/notebook/algo/machine-learning/ml_big_map.html" class="nav-link">
  机器学习算法
</a></li><li class="dropdown-subitem"><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-01.html" class="nav-link">
  吴恩达《机器学习公开课》笔记
</a></li></ul></li></ul></div></div><div class="nav-item"><a href="/notebook/nlp/" class="nav-link">
  NLP
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="/cs-basics/" class="dropdown-title"><span class="title">计算机基础</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/notebook/cs-basics/network/" class="nav-link">
  计算机网络
</a></li></ul></div></div><div class="nav-item"><a href="/notebook/reading/" class="nav-link">
  阅读
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>机器学习</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/notebook/algo/machine-learning/ml_big_map.html" class="sidebar-link">机器学习概览</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>吴恩达《机器学习》笔记</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-01.html" class="sidebar-link">1.机器学习简介</a></li><li><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-02.html" aria-current="page" class="active sidebar-link">2.一元线性回归</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-02.html#_2-1-模型介绍" class="sidebar-link">2.1 模型介绍</a></li><li class="sidebar-sub-header"><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-02.html#_2-2-损失函数" class="sidebar-link">2.2 损失函数</a></li><li class="sidebar-sub-header"><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-02.html#_2-3-损失函数理解-i" class="sidebar-link">2.3 损失函数理解 I</a></li><li class="sidebar-sub-header"><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-02.html#_2-4-损失函数理解-ii" class="sidebar-link">2.4 损失函数理解 II</a></li><li class="sidebar-sub-header"><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-02.html#_2-5-梯度下降" class="sidebar-link">2.5 梯度下降</a></li><li class="sidebar-sub-header"><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-02.html#_2-6-线性回归的梯度下降" class="sidebar-link">2.6 线性回归的梯度下降</a></li></ul></li><li><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-03.html" class="sidebar-link">3.线性代数复习（Optional）</a></li><li><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-04.html" class="sidebar-link">4.多元线性回归</a></li><li><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-05.html" class="sidebar-link">5.Octave教程</a></li><li><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-06.html" class="sidebar-link">6.逻辑回归</a></li><li><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-07.html" class="sidebar-link">7.正则化</a></li><li><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-08.html" class="sidebar-link">8.神经网络: 表征</a></li><li><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-09.html" class="sidebar-link">9.神经网络: 学习</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><p>本内容按照吴恩达公开课《Machine Learning》的 Lecture Slides 进行分类，每一个H1标题对应一个Lecture Slide，每一个H2标题对应Lecture Slide中的一个小章节。</p> <p>本内容是课程的简化总结，适合已经了解机器学习基本概念的人进行回顾以及查漏补缺。</p> <h1 id="_2-一元线性回归"><a href="#_2-一元线性回归" class="header-anchor">#</a> 2 一元线性回归</h1> <h2 id="_2-1-模型介绍"><a href="#_2-1-模型介绍" class="header-anchor">#</a> 2.1 模型介绍</h2> <p>以房价预测举例，x为房屋面积，y为房价，那么通过训练数据来学习到的模型$h(x)=\theta_0+\theta_1\cdot{x}$（二维平面的一条线）就可以通过面积来预测房价。</p> <h2 id="_2-2-损失函数"><a href="#_2-2-损失函数" class="header-anchor">#</a> 2.2 损失函数</h2> <p>如何学习正确的$\theta_0$和$\theta_1$来确定这条线呢？我们希望这条线和样本数据约靠近越好。</p> <p><img src="/notebook/assets/img/image-20200809164252817.d35ad667.png" alt="CostFuction"></p> <h2 id="_2-3-损失函数理解-i"><a href="#_2-3-损失函数理解-i" class="header-anchor">#</a> 2.3 损失函数理解 I</h2> <p>损失函数的目的是<strong>最小化均方误差</strong>：</p> <p>$$
J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2
$$
其中<strong>m</strong>为样本个数，$h_{\theta}(x)$为模型函数，x(i) y(i)分别对应样本点。</p> <h2 id="_2-4-损失函数理解-ii"><a href="#_2-4-损失函数理解-ii" class="header-anchor">#</a> 2.4 损失函数理解 II</h2> <p><strong>模型</strong>：$h(x)=\theta_0+\theta_1\cdot{x}$</p> <p><strong>参数</strong>：$\theta_0$，$\theta_1$</p> <p><strong>损失函数</strong>：$J(\theta_0, \theta_1)=\frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2$</p> <p><strong>目标</strong>：通过改变$\theta_0$，$\theta_1$来最小化$J(\theta_0, \theta_1)$</p> <p><img src="/notebook/assets/img/image-20200809170201465.defdc5be.png" alt="image-20200809170201465"></p> <blockquote><p>编者注：后来我们知道，最小化损失函数的过程就是一个凸优化问题</p></blockquote> <h2 id="_2-5-梯度下降"><a href="#_2-5-梯度下降" class="header-anchor">#</a> 2.5 梯度下降</h2> <p>重复下面步骤，直到<strong>收敛</strong>：</p> <p>$\theta_j := \theta_j - \alpha\frac{\part}{\part\theta_j}J(\theta_0,\theta_1)$</p> <blockquote><p><strong>重点</strong>：一定要一次性计算好所有方向上的梯度，然后一次性更新所有$\theta$参数。以下步骤是错误的：</p> <p>$temp0 := \theta_0 - \alpha\frac{\part}{\part\theta_0}J(\theta_0,\theta_1)$</p> <p>$\theta_0 := temp0$</p> <p>$temp1 := \theta_1 - \alpha\frac{\part}{\part\theta_1}J(\theta_0,\theta_1)$</p> <p>$\theta_1 := temp1$</p> <p>（此举会导致参数按每个梯度方向都更新一次）</p></blockquote> <p>$\alpha$：<strong>学习率</strong>。太小会导致学习太慢，太大会导致跳过最低点甚至损失函数发散</p> <h2 id="_2-6-线性回归的梯度下降"><a href="#_2-6-线性回归的梯度下降" class="header-anchor">#</a> 2.6 线性回归的梯度下降</h2> <p><strong>求导</strong>可得：</p> <p>$\frac{\part}{\part\theta_0}J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}({x^{(i)})}-y^{(i)})$</p> <p>$\frac{\part}{\part\theta_1}J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}({x^{(i)})}-y^{(i)})\cdot{x^{(i)}}$</p> <p><img src="/notebook/assets/img/image-20200809171947353.2e0e45a3.png" alt="image-20200809171947353"></p> <p><strong>批梯度下降</strong>：对应损失函数中的m，批梯度下降使用所有的训练数据</p> <p><strong>随机梯度下降</strong>：一次训练不采用全部的训练数据（降低m），目的是减少计算量</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-01.html" class="prev">
        1.机器学习简介
      </a></span> <span class="next"><a href="/notebook/algo/machine-learning/Machine-Learning-Andrew-Ng/Notes-03.html">
        3.线性代数复习（Optional）
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/notebook/assets/js/app.1fe6bb95.js" defer></script><script src="/notebook/assets/js/2.4f4438fc.js" defer></script><script src="/notebook/assets/js/3.a73bf4c2.js" defer></script>
  </body>
</html>
