(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{379:function(v,_,t){"use strict";t.r(_);var a=t(40),s=Object(a.a)({},(function(){var v=this,_=v.$createElement,t=v._self._c||_;return t("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[t("p",[v._v("学习的本质都是最优化问题")]),v._v(" "),t("h1",{attrs:{id:"学习目标"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#学习目标"}},[v._v("#")]),v._v(" 学习目标")]),v._v(" "),t("p",[v._v("分类")]),v._v(" "),t("p",[v._v("回归")]),v._v(" "),t("h1",{attrs:{id:"模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#模型"}},[v._v("#")]),v._v(" 模型")]),v._v(" "),t("h2",{attrs:{id:"svm"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#svm"}},[v._v("#")]),v._v(" SVM")]),v._v(" "),t("h2",{attrs:{id:"树模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#树模型"}},[v._v("#")]),v._v(" 树模型")]),v._v(" "),t("p",[v._v("ID3")]),v._v(" "),t("p",[v._v("C4.5")]),v._v(" "),t("p",[v._v("CART")]),v._v(" "),t("p",[v._v("XGBoost")]),v._v(" "),t("p",[v._v("LightGBM")]),v._v(" "),t("p",[v._v("CATBoost")]),v._v(" "),t("h2",{attrs:{id:"神经网络"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#神经网络"}},[v._v("#")]),v._v(" 神经网络")]),v._v(" "),t("p",[v._v("Dense (Fully Connected)")]),v._v(" "),t("p",[v._v("CNN")]),v._v(" "),t("p",[v._v("RNN")]),v._v(" "),t("h1",{attrs:{id:"激活函数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#激活函数"}},[v._v("#")]),v._v(" 激活函数")]),v._v(" "),t("p",[v._v("将线性函数转化为非线性函数")]),v._v(" "),t("p",[v._v("sigmoid")]),v._v(" "),t("p",[v._v("softmax")]),v._v(" "),t("p",[v._v("tanh")]),v._v(" "),t("p",[v._v("relu")]),v._v(" "),t("p",[v._v("leakyRelu")]),v._v(" "),t("h1",{attrs:{id:"目标函数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#目标函数"}},[v._v("#")]),v._v(" 目标函数")]),v._v(" "),t("h2",{attrs:{id:"损失函数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#损失函数"}},[v._v("#")]),v._v(" 损失函数")]),v._v(" "),t("p",[v._v("最小二乘")]),v._v(" "),t("p",[v._v("*极大似然")]),v._v(" "),t("p",[v._v("logLoss/logitLoss")]),v._v(" "),t("p",[v._v("cross-entropy Loss")]),v._v(" "),t("p",[v._v("Focal Loss")]),v._v(" "),t("h2",{attrs:{id:"正则化项"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#正则化项"}},[v._v("#")]),v._v(" 正则化项")]),v._v(" "),t("p",[v._v("L1")]),v._v(" "),t("p",[v._v("L2")]),v._v(" "),t("h1",{attrs:{id:"优化算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#优化算法"}},[v._v("#")]),v._v(" 优化算法")]),v._v(" "),t("p",[v._v("梯度下降 ("),t("a",{attrs:{href:"https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c",target:"_blank",rel:"noopener noreferrer"}},[v._v("可视化"),t("OutboundLink")],1),v._v(")")]),v._v(" "),t("ul",[t("li",[v._v("vanilla gradient decent")]),v._v(" "),t("li",[v._v("Momentum")]),v._v(" "),t("li",[v._v("AdaGrad")]),v._v(" "),t("li",[v._v("RMSProp")]),v._v(" "),t("li",[v._v("Adam")])]),v._v(" "),t("p",[v._v("牛顿法")]),v._v(" "),t("p",[v._v("拟牛顿法")]),v._v(" "),t("p",[v._v("DFP")]),v._v(" "),t("p",[v._v("BFGS")]),v._v(" "),t("p",[v._v("Broyden")]),v._v(" "),t("p",[v._v("https://zhuanlan.zhihu.com/p/37524275")]),v._v(" "),t("p",[v._v("http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf")]),v._v(" "),t("h1",{attrs:{id:"评价指标"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#评价指标"}},[v._v("#")]),v._v(" 评价指标")]),v._v(" "),t("p",[v._v("Accuracy, Precision, Recall")]),v._v(" "),t("p",[v._v("F1-score")]),v._v(" "),t("p",[v._v("ROC/AUC")])])}),[],!1,null,null,null);_.default=s.exports}}]);