(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{394:function(t,v,a){"use strict";a.r(v);var _=a(42),s=Object(_.a)({},(function(){var t=this,v=t.$createElement,a=t._self._c||v;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"机器学习概览"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#机器学习概览"}},[t._v("#")]),t._v(" 机器学习概览")]),t._v(" "),a("p",[t._v("学习的本质都是最优化问题")]),t._v(" "),a("h2",{attrs:{id:"学习目标"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#学习目标"}},[t._v("#")]),t._v(" 学习目标")]),t._v(" "),a("p",[t._v("分类")]),t._v(" "),a("p",[t._v("回归")]),t._v(" "),a("h2",{attrs:{id:"模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#模型"}},[t._v("#")]),t._v(" 模型")]),t._v(" "),a("h3",{attrs:{id:"svm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#svm"}},[t._v("#")]),t._v(" SVM")]),t._v(" "),a("h3",{attrs:{id:"树模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#树模型"}},[t._v("#")]),t._v(" 树模型")]),t._v(" "),a("p",[t._v("ID3")]),t._v(" "),a("p",[t._v("C4.5")]),t._v(" "),a("p",[t._v("CART")]),t._v(" "),a("p",[t._v("XGBoost")]),t._v(" "),a("p",[t._v("LightGBM")]),t._v(" "),a("p",[t._v("CATBoost")]),t._v(" "),a("h3",{attrs:{id:"神经网络"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#神经网络"}},[t._v("#")]),t._v(" 神经网络")]),t._v(" "),a("p",[t._v("Dense (Fully Connected)")]),t._v(" "),a("p",[t._v("CNN")]),t._v(" "),a("p",[t._v("RNN")]),t._v(" "),a("h3",{attrs:{id:"激活函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#激活函数"}},[t._v("#")]),t._v(" 激活函数")]),t._v(" "),a("p",[t._v("将线性函数转化为非线性函数，激活函数一般来讲也是模型的一部分")]),t._v(" "),a("p",[t._v("sigmoid")]),t._v(" "),a("p",[t._v("softmax")]),t._v(" "),a("p",[t._v("tanh")]),t._v(" "),a("p",[t._v("relu")]),t._v(" "),a("p",[t._v("leakyRelu")]),t._v(" "),a("h2",{attrs:{id:"目标函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#目标函数"}},[t._v("#")]),t._v(" 目标函数")]),t._v(" "),a("h3",{attrs:{id:"损失函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#损失函数"}},[t._v("#")]),t._v(" 损失函数")]),t._v(" "),a("p",[t._v("最小二乘")]),t._v(" "),a("p",[t._v("*极大似然")]),t._v(" "),a("p",[t._v("logLoss/logitLoss")]),t._v(" "),a("p",[t._v("cross-entropy Loss")]),t._v(" "),a("p",[t._v("Focal Loss")]),t._v(" "),a("h3",{attrs:{id:"正则化项"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#正则化项"}},[t._v("#")]),t._v(" 正则化项")]),t._v(" "),a("p",[t._v("L1")]),t._v(" "),a("p",[t._v("L2")]),t._v(" "),a("h2",{attrs:{id:"优化算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#优化算法"}},[t._v("#")]),t._v(" 优化算法")]),t._v(" "),a("p",[t._v("梯度下降 ("),a("a",{attrs:{href:"https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c",target:"_blank",rel:"noopener noreferrer"}},[t._v("可视化"),a("OutboundLink")],1),t._v(")")]),t._v(" "),a("ul",[a("li",[t._v("vanilla gradient decent")]),t._v(" "),a("li",[t._v("Momentum")]),t._v(" "),a("li",[t._v("AdaGrad")]),t._v(" "),a("li",[t._v("RMSProp")]),t._v(" "),a("li",[t._v("Adam")])]),t._v(" "),a("p",[t._v("牛顿法")]),t._v(" "),a("p",[t._v("拟牛顿法")]),t._v(" "),a("p",[t._v("DFP")]),t._v(" "),a("p",[t._v("BFGS")]),t._v(" "),a("p",[t._v("Broyden")]),t._v(" "),a("p",[t._v("https://zhuanlan.zhihu.com/p/37524275")]),t._v(" "),a("p",[t._v("http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf")]),t._v(" "),a("h2",{attrs:{id:"评价指标"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#评价指标"}},[t._v("#")]),t._v(" 评价指标")]),t._v(" "),a("p",[t._v("Accuracy, Precision, Recall")]),t._v(" "),a("p",[t._v("F1-score")]),t._v(" "),a("p",[t._v("ROC/AUC")])])}),[],!1,null,null,null);v.default=s.exports}}]);